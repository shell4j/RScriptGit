FROM Emails e
INNER JOIN Persons p ON e.SenderPersonId=P.Id
WHERE p.Name='Hillary Clinton'
AND e.ExtractedBodyText != ''
ORDER BY RANDOM()")
library(tm)
library(wordcloud)
makeWordCloud <- function(documents) {
corpus = Corpus(VectorSource(tolower(documents)))
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords("english"))
frequencies = DocumentTermMatrix(corpus)
word_frequencies = as.data.frame(as.matrix(frequencies))
words <- colnames(word_frequencies)
freq <- colSums(word_frequencies)
wordcloud(words, freq,
min.freq=sort(freq, decreasing=TRUE)[[100]],
colors=brewer.pal(8, "Dark2"),
random.color=TRUE)
}
makeWordCloud(emailsFromHillary[["EmailBody"]])
library(RSQLite) #for sqlite
# let's get the data
db <- dbConnect(dbDriver("SQLite"), "../input/database.sqlite")
#I need here only the emails
Emails <- data.frame(dbGetQuery(db,"SELECT * FROM Emails"))
library('syuzhet') #for sentiments analysis
###################################
#  Sentiment Analysis             #
###################################
d<-get_nrc_sentiment(Emails$RawText)
library(readr)
library(syuzhet)
library(RSQLite)
db <- dbConnect(dbDriver("SQLite"), "D:/Kaggle/HillaryEmail/output/database.sqlite")
commonSenders <- dbGetQuery(db, "
SELECT p.Name, COUNT(p.Name) NumEmailsSent
FROM Emails e
INNER JOIN Persons p ON e.SenderPersonId=p.Id
GROUP BY p.Name
ORDER BY COUNT(p.Name) DESC
LIMIT 20")
library(ggplot2)
ggplot(commonSenders, aes(x=reorder(Name, NumEmailsSent), y=NumEmailsSent)) +
geom_bar(stat="identity", fill="#53cfff") +
coord_flip() +
theme_light(base_size=16) +
xlab("") +
ylab("Number of Emails Sent") +
theme(plot.title=element_text(size=14))
commonRecipients <- dbGetQuery(db, "
SELECT p.Name, COUNT(p.Name) NumEmailsReceived
FROM Emails e
INNER JOIN EmailReceivers r ON r.EmailId=e.Id
INNER JOIN Persons p ON r.PersonId=p.Id
GROUP BY p.Name
ORDER BY COUNT(p.Name) DESC
LIMIT 10")
library(ggplot2)
ggplot(commonRecipients, aes(x=reorder(Name, NumEmailsReceived), y=NumEmailsReceived)) +
geom_bar(stat="identity", fill="#53cfff") +
coord_flip() +
theme_light(base_size=16) +
xlab("") +
ylab("Number of Emails Received") +
theme(plot.title=element_text(size=14))
commonRecipients <- dbGetQuery(db, "
SELECT p.Name, COUNT(p.Name) NumEmailsReceived
FROM Emails e
INNER JOIN EmailReceivers r ON r.EmailId=e.Id
INNER JOIN Persons p ON r.PersonId=p.Id
GROUP BY p.Name
ORDER BY COUNT(p.Name) DESC
LIMIT 15")
library(ggplot2)
ggplot(commonRecipients, aes(x=reorder(Name, NumEmailsReceived), y=NumEmailsReceived)) +
geom_bar(stat="identity", fill="#53cfff") +
coord_flip() +
theme_light(base_size=16) +
xlab("") +
ylab("Number of Emails Received") +
theme(plot.title=element_text(size=14))
emailsFromHillary <- dbGetQuery(db, "
SELECT p.Name Sender,
ExtractedBodyText EmailBody
FROM Emails e
INNER JOIN Persons p ON e.SenderPersonId=P.Id
WHERE p.Name='Hillary Clinton'
AND e.ExtractedBodyText != ''
ORDER BY RANDOM()")
summary(emailsFromHillary )
type(emailsFromHillary)
class(emailsFromHillary)
??wordcloud
library(tm)
library(wordcloud)
makeWordCloud <- function(documents) {
corpus = Corpus(VectorSource(tolower(documents)))
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords("english"))
frequencies = DocumentTermMatrix(corpus)
word_frequencies = as.data.frame(as.matrix(frequencies))
words <- colnames(word_frequencies)
freq <- colSums(word_frequencies)
wordcloud(words, freq,
min.freq=sort(freq, decreasing=TRUE)[[300]],
colors=brewer.pal(8, "Dark2"),
random.color=TRUE)
}
makeWordCloud(emailsFromHillary[["EmailBody"]])
library(tm)
library(wordcloud)
makeWordCloud <- function(documents) {
corpus = Corpus(VectorSource(tolower(documents)))
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords("english"))
frequencies = DocumentTermMatrix(corpus)
word_frequencies = as.data.frame(as.matrix(frequencies))
words <- colnames(word_frequencies)
freq <- colSums(word_frequencies)
wordcloud(words, freq,
min.freq=sort(freq, decreasing=TRUE)[[400]],
colors=brewer.pal(8, "Dark2"),
random.color=TRUE)
}
makeWordCloud(emailsFromHillary[["EmailBody"]])
emailsToHillary <- dbGetQuery(db, "
SELECT p.Name Recipient,
ExtractedBodyText EmailBody
FROM Emails e
INNER JOIN EmailReceivers r ON r.EmailId=e.Id
INNER JOIN Persons p ON r.PersonId=P.Id
WHERE p.Name='Hillary Clinton'
AND e.ExtractedBodyText != ''
ORDER BY RANDOM()")
makeWordCloud(emailsToHillary[["EmailBody"]])
source('D:/RScriptGit/sentiment1.R', encoding = 'UTF-8')
source('D:/RScriptGit/sentiment1.R', encoding = 'UTF-8')
library(readr)
library(syuzhet)
library(RSQLite)
db <- dbConnect(dbDriver("SQLite"), "D:/Kaggle/HillaryEmail/output/database.sqlite")
#library(dplyr)
###选出hillary发送的文件内容
emailsFromHillary <- dbGetQuery(db, "
SELECT p.Name Sender,
ExtractedBodyText EmailBody
FROM Emails e
INNER JOIN Persons p ON e.SenderPersonId=P.Id
WHERE p.Name='Hillary Clinton'
AND e.ExtractedBodyText != ''
ORDER BY RANDOM()")
d<-get_nrc_sentiment(Emails$RawText)
td<-data.frame(t(d))
td_new <- data.frame(rowSums(td[2:7945]))
source('D:/RScriptGit/sentiment1.R', encoding = 'UTF-8')
source('D:/RScriptGit/sentiment1.R', encoding = 'UTF-8')
Emails <- data.frame(dbGetQuery(db,"SELECT * FROM Emails"))
###################################
#  Sentiment Analysis             #
###################################
d<-get_nrc_sentiment(Emails$RawText)
td<-data.frame(t(d))
td_new <- data.frame(rowSums(td[2:7945]))
#Transformation and  cleaning
names(td_new)[1] <- "count"
td_new <- cbind("sentiment" = rownames(td_new), td_new)
rownames(td_new) <- NULL
td_new2<-td_new[1:8,]
#Vizualisation
library("ggplot2")
qplot(sentiment, data=td_new2, weight=count, geom="histogram",fill=sentiment)+ggtitle("sentiment Email")
source('D:/RScriptGit/sentiment1.R', encoding = 'UTF-8')
summary(d)
class(d)
??get_nrc_sentiment
?syuzhet
??syuzhet
pander::pandoc.table(td_new2[, 1:8])
install.packages('pander')
pander::pandoc.table(td_new2[, 1:8])
pander::pandoc.table(td_new2[1:8,])
head(d)
source('D:/RScriptGit/sentiment1.R', encoding = 'UTF-8')
t(d)
??get_stanford_sentiment
sdf=get_stanford_sentiment(Emails$RawText)
library(syuzhet)
sdf=get_stanford_sentiment(Emails$RawText)
??get_percentage_values()
get_percentage_values(d)
t=get_percentage_values(d)
d
install.packages('lda')
install.packages('topicmodels')
library(topicmodels)
??"TopicModel-class"
??lda
source('D:/RScriptGit/topicModels.R')
source('D:/RScriptGit/topicModels.R')
num_topics = 15 # Max that memory limit can handle
vcorp = VCorpus(VectorSource(emailsFromHillary$ExtractedBodyText))
docterm_mat = DocumentTermMatrix(vcorp)
drop_inds = which(rowSums(as.matrix(docterm_mat))==0)
docterm_mat = docterm_mat[-drop_inds,]
num_topics = 15 # Max that memory limit can handle
fitted_lda = LDA(docterm_mat,k=num_topics)
summary(fitted_lda)
terms(fitted_lda,num_terms)
summary(emailsFromHillary)
vcorp = VCorpus(VectorSource(emailsFromHillary$EmailBody))
docterm_mat = DocumentTermMatrix(vcorp)
drop_inds = which(rowSums(as.matrix(docterm_mat))==0)
docterm_mat = docterm_mat[-drop_inds,]
num_topics = 15 # Max that memory limit can handle
fitted_lda = LDA(docterm_mat,k=num_topics)
terms(fitted_lda,num_terms)
source('D:/RScriptGit/sentiment1.R', encoding = 'UTF-8')
docterm_mat = DocumentTermMatrix(vcorp)
source('D:/RScriptGit/topicmodels1.R', encoding = 'UTF-8')
library(readr)
library(RSQLite)
library(topicmodels)
library(tm)
db <- dbConnect(dbDriver("SQLite"), "D:/Kaggle/HillaryEmail/output/database.sqlite")
emailsToHillary <- dbGetQuery(db, "
SELECT p.Name Recipient,
ExtractedBodyText EmailBody
FROM Emails e
INNER JOIN EmailReceivers r ON r.EmailId=e.Id
INNER JOIN Persons p ON r.PersonId=P.Id
WHERE p.Name='Hillary Clinton'
AND e.ExtractedBodyText != ''
ORDER BY RANDOM()")
vcorp = VCorpus(VectorSource(emailsToHillary$EmailBody))
docterm_mat = DocumentTermMatrix(vcorp)
drop_inds = which(rowSums(as.matrix(docterm_mat))==0)
docterm_mat = docterm_mat[-drop_inds,]
install.packages("drat", repos="https://cran.rstudio.com")
drat:::addRepo("dmlc")
install.packages("mxnet")
require(mxnet)
require(methods)
shape = c(1, 1)
lr = 0.01
x = mx.nd.ones(shape)
y = mx.nd.zeros(shape)
print(x)
n = 1000
tic = proc.time()
for (i in 1 : n) {
y = y + x *lr
}
toc = proc.time() - tic
as.array(y)
print(toc)
require(mxnet)
require(methods)
install.packages(Rcpp)
install.packages('Rcpp')
require(mxnet)
require(methods)
install.packages("mxnet")
caret()
library('syuzhet')
??syuzhet
library(topicmodels)
??"TopicModel-class"
library(readr)
library(syuzhet)
library(RSQLite)
db <- dbConnect(dbDriver("SQLite"), "D:/Kaggle/HillaryEmail/output/database.sqlite")
#library(dplyr)
###希拉里发送邮件的情感分析
Emails <- dbGetQuery(db, "
SELECT p.Name Sender,
ExtractedBodyText EmailBody
FROM Emails e
INNER JOIN Persons p ON e.SenderPersonId=P.Id
WHERE p.Name='Hillary Clinton'
AND e.ExtractedBodyText != ''
ORDER BY RANDOM()")
class(Emails)
head(Emails,2)
d<-get_nrc_sentiment(Emails$EmailBody)
td<-data.frame(t(d))
length(Emails)
td<-data.frame(t(d))
names(td_new)[1] <- "count"
td_new <- cbind("sentiment" = rownames(td_new), td_new)
rownames(td_new) <- NULL
td_new2<-td_new[1:8,]
td_new <- data.frame(rowSums(td[2:7945]))
#Transformation and  cleaning
names(td_new)[1] <- "count"
td_new <- cbind("sentiment" = rownames(td_new), td_new)
rownames(td_new) <- NULL
td_new2<-td_new[1:8,]
td
summary(td)
td_new <- data.frame(rowSums(td[2:1882]))
names(td_new)[1] <- "count"
td_new <- cbind("sentiment" = rownames(td_new), td_new)
rownames(td_new) <- NULL
td_new2<-td_new[1:8,]names(td_new)[1] <- "count"
td_new <- cbind("sentiment" = rownames(td_new), td_new)
rownames(td_new) <- NULL
td_new2<-td_new[1:8,]
td_new <- data.frame(rowSums(td[2:1882]))
#Transformation and  cleaning
names(td_new)[1] <- "count"
td_new <- cbind("sentiment" = rownames(td_new), td_new)
rownames(td_new) <- NULL
td_new2<-td_new[1:8,]
library("ggplot2")
qplot(sentiment, data=td_new2, weight=count, geom="histogram",fill=sentiment)+ggtitle("Hillary's sending sentiment Email")
Emails <- dbGetQuery(db, "
SELECT p.Name Recipient,
ExtractedBodyText EmailBody
FROM Emails e
INNER JOIN EmailReceivers r ON r.EmailId=e.Id
INNER JOIN Persons p ON r.PersonId=P.Id
WHERE p.Name='Hillary Clinton'
AND e.ExtractedBodyText != ''
ORDER BY RANDOM()")
d<-get_nrc_sentiment(Emails$EmailBody)
#d1=get_sentiment(Emails$RawText)
td<-data.frame(t(d))
td_new <- data.frame(rowSums(td[2:4715]))
#Transformation and  cleaning
names(td_new)[1] <- "count"
td_new <- cbind("sentiment" = rownames(td_new), td_new)
rownames(td_new) <- NULL
td_new2<-td_new[1:8,]
library("ggplot2")
qplot(sentiment, data=td_new2, weight=count, geom="histogram",fill=sentiment)+ggtitle("Hillary's sending sentiment Email")
vcorp = VCorpus(VectorSource(emailsFromHillary$EmailBody))
docterm_mat = DocumentTermMatrix(vcorp)
drop_inds = which(rowSums(as.matrix(docterm_mat))==0)
docterm_mat = docterm_mat[-drop_inds,]
num_topics = 5 # Max that memory limit can handle
fitted_lda = LDA(docterm_mat,k=num_topics)
num_terms = 10
terms(fitted_lda,num_terms)
emailsFromHillary <- dbGetQuery(db, "
SELECT p.Name Sender,
ExtractedBodyText EmailBody
FROM Emails e
INNER JOIN Persons p ON e.SenderPersonId=P.Id
WHERE p.Name='Hillary Clinton'
AND e.ExtractedBodyText != ''
ORDER BY RANDOM()")
vcorp = VCorpus(VectorSource(emailsFromHillary$EmailBody))
docterm_mat = DocumentTermMatrix(vcorp)
drop_inds = which(rowSums(as.matrix(docterm_mat))==0)
docterm_mat = docterm_mat[-drop_inds,]
num_topics = 5 # Max that memory limit can handle
fitted_lda = LDA(docterm_mat,k=num_topics)
num_terms = 10
terms(fitted_lda,num_terms)
library(topicmodels)
library(tm)
db <- dbConnect(dbDriver("SQLite"), "D:/Kaggle/HillaryEmail/output/database.sqlite")
emailsFromHillary <- dbGetQuery(db, "
SELECT p.Name Sender,
ExtractedBodyText EmailBody
FROM Emails e
INNER JOIN Persons p ON e.SenderPersonId=P.Id
WHERE p.Name='Hillary Clinton'
AND e.ExtractedBodyText != ''
ORDER BY RANDOM()")
vcorp = VCorpus(VectorSource(emailsFromHillary$EmailBody))
docterm_mat = DocumentTermMatrix(vcorp)
drop_inds = which(rowSums(as.matrix(docterm_mat))==0)
docterm_mat = docterm_mat[-drop_inds,]
num_topics = 5 # Max that memory limit can handle
fitted_lda = LDA(docterm_mat,k=num_topics)
num_terms = 10
terms(fitted_lda,num_terms)
num_topics = 10 # Max that memory limit can handle
fitted_lda = LDA(docterm_mat,k=num_topics)
num_terms = 10
terms(fitted_lda,num_terms)
aa=terms(fitted_lda,num_terms)
write_csv("D:/Kaggle/HillaryEmail/topicOutput.csv",aa)
aa
aa=as.data.frame(aa)
write_csv("D:/Kaggle/HillaryEmail/topicOutput.csv",aa)
??write_csv
write_csv(aa,"D:/Kaggle/HillaryEmail/topicOutput.csv")
num_topics = 20 # Max that memory limit can handle
fitted_lda = LDA(docterm_mat,k=num_topics)
num_terms = 10
terms(fitted_lda,num_terms)
aa=terms(fitted_lda,num_terms)
write_csv(aa,"D:/Kaggle/HillaryEmail/topicOutput.csv")
aa=terms(fitted_lda,num_terms)
aa=as.data.frame(aa)
write_csv(aa,"D:/Kaggle/HillaryEmail/topicOutput.csv
)
/
\
""
")
aa=terms(fitted_lda,num_terms)
aa=as.data.frame(aa)
write_csv(aa,"D:/Kaggle/HillaryEmail/topicOutput.csv")
aa=terms(fitted_lda,num_terms)
aa=as.data.frame(aa)
write_csv(aa,"D:/Kaggle/HillaryEmail/topicOutput.csv")
num_topics = 20 # Max that memory limit can handle
fitted_lda = LDA(docterm_mat,k=num_topics)
num_terms = 10
terms(fitted_lda,num_terms)
aa=terms(fitted_lda,num_terms)
aa=as.data.frame(aa)
write_csv(aa,"D:/Kaggle/HillaryEmail/topicOutput.csv")
library('syuzhet')
??syuzhet
library(readr)
library(syuzhet)
library(RSQLite)
db <- dbConnect(dbDriver("SQLite"), "D:/Kaggle/HillaryEmail/output/database.sqlite")
#library(dplyr)
Emails <- data.frame(dbGetQuery(db,"SELECT * FROM Emails"))
d<-get_nrc_sentiment(Emails$RawText)
head(d)
sum(d)
afinn_vector <- get_sentiment(Emails$RawText, method="afinn")
head(afinn_vector)
afinn_vector
a=afinn_vector[]
summary(afinn_vector)
mode(afinn_vector)
a=afinn_vector[afinn_vector>0]
a
b=afinn_vector[afinn_vector<=0]
count(a)
sum(a)
sum(b)
??ggplot
as.data.frame(sum(a),sum(b))
aa=as.data.frame(sum(a),sum(b))
aa
aa=aa[row.names(c("negtive","postive"))]
aa
aa=cbind(row.names(c("negtive","postive")),aa)
aa=c(14164,41960)
aa=as.data.frame(aa,row.names = c("negtive","postive"))
aa
ggplot(aa)
library(ggplot2)
ggplot(aa)
aa=as.data.frame(aa,column.names = c("negtive","postive"))
aa
ggplot(aa)
barplot(aa)
barplot(c(14164,41960))
?barplot
barplot(c(14164,41960),col=c("negetive","positive"),)
barplot(c(14164,41960),names=c("negetive","positive"),col = c("lightblue", "mistyrose"))
library(readr)
library(RSQLite)
library(topicmodels)
library(tm)
db <- dbConnect(dbDriver("SQLite"), "D:/Kaggle/HillaryEmail/output/database.sqlite")
emailsToHillary <- dbGetQuery(db, "
SELECT p.Name Recipient,
ExtractedBodyText EmailBody
FROM Emails e
INNER JOIN EmailReceivers r ON r.EmailId=e.Id
INNER JOIN Persons p ON r.PersonId=P.Id
WHERE p.Name='Hillary Clinton'
AND e.ExtractedBodyText != ''
ORDER BY RANDOM()")
vcorp = VCorpus(VectorSource(emailsToHillary$EmailBody))
docterm_mat = DocumentTermMatrix(vcorp)
drop_inds = which(rowSums(as.matrix(docterm_mat))==0)
docterm_mat = docterm_mat[-drop_inds,]
num_topics = 25 # Max that memory limit can handle
fitted_lda = LDA(docterm_mat,k=num_topics)
summary(fitted_lda)
num_terms = 20
aa=terms(fitted_lda,num_terms)
aa
write_csv(aa,"D:/Kaggle/HillaryEmail/topicOutput.csv")
write_csv(as.data.frame(aa),"D:/Kaggle/HillaryEmail/topicOutput.csv")
write_csv(as.data.frame(aa),"D:/Kaggle/HillaryEmail/topicOutput.csv")
library(readr)
library(RSQLite)
library(topicmodels)
library(tm)
db <- dbConnect(dbDriver("SQLite"), "D:/Kaggle/HillaryEmail/output/database.sqlite")
emailsToHillary <- dbGetQuery(db, "
SELECT p.Name Recipient,
ExtractedBodyText EmailBody
FROM Emails e
INNER JOIN EmailReceivers r ON r.EmailId=e.Id
INNER JOIN Persons p ON r.PersonId=P.Id
WHERE p.Name='Hillary Clinton'
AND e.ExtractedBodyText != ''
ORDER BY RANDOM()")
vcorp = VCorpus(VectorSource(emailsToHillary$EmailBody))
docterm_mat = DocumentTermMatrix(vcorp)
drop_inds = which(rowSums(as.matrix(docterm_mat))==0)
docterm_mat = docterm_mat[-drop_inds,]
num_topics = 25 # Max that memory limit can handle
fitted_lda = LDA(docterm_mat,k=num_topics)
num_terms = 20
aa=terms(fitted_lda,num_terms)
write_csv(as.data.frame(aa),"D:/Kaggle/HillaryEmail/topicOutput1.csv")
install.packages('igraph')
