library(readr) # CSV file I/O, e.g. the read_csv function
library(xgboost)
# Input data files are available in the "../input/" directory.
# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory
# Reading the data
#dat_train <- read.csv("../input/train.csv", stringsAsFactors = F)
#dat_test <- read.csv("../input/test.csv", stringsAsFactors = F)
dat_train=read_csv("D:/santander/train.csv")
dat_test=read_csv("D:/santander/test.csv")
# Mergin the test and train data
dat_test$TARGET <- NA
all_dat <- rbind(dat_train, dat_test)
# Removing the constant variables
train_names <- names(dat_train)[-1]
for (i in train_names)
{
if (class(all_dat[[i]]) == "integer")
{
u <- unique(all_dat[[i]])
if (length(u) == 1)
{
all_dat[[i]] <- NULL
}
train_names <- names(all_dat)[-1]
fac <- data.frame(fac = integer())
for(i in 1:length(train_names))
{
if(i != length(train_names))
{
for (k in (i+1):length(train_names))
{
if(identical(all_dat[,i], all_dat[,k]) == TRUE)
{
fac <- rbind(fac, data.frame(fac = k))
}
same <- unique(fac$fac)
all_dat <- all_dat[,-same]
# Splitting the data for model
train <- all_dat[1:nrow(dat_train), ]
test <- all_dat[-(1:nrow(dat_train)), ]
y=as.numeric(dat_train$TARGET)
train[is.na(train)]=0
test[is.na(test)]=0
pca=princomp(train[,-c(train$ID,train$TARGET)])
train1=predict(pca,train[,-c(train$ID,train$TARGET)])
ncol(train1)
ncol(train)
test=predict(pca,test[,-c(test$ID,test$TARGET)])
test=predict(pca,test[,-c(test$ID)])
ncol(test)
test=predict(pca,test[,-c(test$ID,test$TARGET)])
dtrain=train[,-c(train$ID,train$TARGET)]
ncol(dtrain)
train <- all_dat[1:nrow(dat_train), ]
test <- all_dat[-(1:nrow(dat_train)), ]
#y=as.numeric(dat_train$TARGET)
train[is.na(train)]=0
test[is.na(test)]=0
ncol(dtrain)
ncol(train)
dtrain=train[,-c(train$ID,train$TARGET)]
pca=princomp(train[,-c(train$ID,train$TARGET)])
ncol(dtrain)
ncol(train[,-c(train$ID,train$TARGET)])
ncol(train)
dtrain=train[,-c(train$ID,train$TARGET)]
ncol(dtrain)
a=names(dtrain)
b=names(dtrain)
b=names(train)
library(dplyr)
dtrain=select(train,-c(ID,TARGET))
dtest=select(test,-c(ID,TARGET))
pca=princomp(dtrain)
train1=predict(pca,dtrain)
test1=predict(pca,dtest)
test1$chr
param1 <- list("objective" = "binary:logistic",
booster = "gbtree",
"eval_metric" = "auc",
colsample_bytree = 0.85,
subsample = 0.75)
xgb.model=xgboost(data = dtrain),
label=y,
params = param1,
nrounds = 80,
max.depth = 10,
eta = 0.02,
maximize = T)
xgb.model=xgboost(data = dtrain,
label=y,
params = param1,
nrounds = 80,
max.depth = 10,
eta = 0.02,
maximize = T)
summary(dtrain)
ncol(dtrain)
ncol(train1)
pca=princomp(dtrain,cor=TRUE)
train1=predict(pca,dtrain)
?predict.princomp
pc.cr <- princomp(USArrests, cor = TRUE)
summary(pc.cr)
plot(pc.cr)
biplot(pc.cr)
summary(USArrests)
nrow(USArrests)
View(stackloss)
?predict
summary(pc.cr)
print(pc.cr)
??knn
train <- rbind(iris3[1:25,,1], iris3[1:25,,2], iris3[1:25,,3])
test <- rbind(iris3[26:50,,1], iris3[26:50,,2], iris3[26:50,,3])
cl <- factor(c(rep("s",25), rep("c",25), rep("v",25)))
t=knn(train, test, cl, k = 3, prob=TRUE)
library(class)
train <- rbind(iris3[1:25,,1], iris3[1:25,,2], iris3[1:25,,3])
test <- rbind(iris3[26:50,,1], iris3[26:50,,2], iris3[26:50,,3])
cl <- factor(c(rep("s",25), rep("c",25), rep("v",25)))
t=knn(train, test, cl, k = 3, prob=TRUE)
summary(t)
t
mode(c)
mode(t)
View(iris)
library(readr)
library(xgboost)
library(stats)
train=read_csv("D:/santander/train.csv")
test=read_csv("D:/santander/test.csv")
problems()
problems(train)
?"table"
?rpart
install.packages('rpart')
train <- rbind(iris3[,,1], iris3[,,2], iris3[,,3])
a=iris[,,1]
library(readr)
library(xgboost)
library(stats)
train=read_csv("D:/santander/train.csv")
test=read_csv("D:/santander/test.csv")
summary(train[,2])
summary(train[,3])
summary(train[,1])
summary(train[,0])
as.factor(iris$Species)
a=as.factor(iris$Species)
summary(a)
mode(a)
mode(iris$Species)
summary(train[,4])
summary(train[,5:10])
summary(train[,10:15])
summary(train[,15:20])
summary(train[,21:25])
summary(train[,26:35])
summary(train[,36:45])
summary(train[,46:55])
library(readr)
library(xgboost)
library(stats)
train=read_csv("D:/santander/train.csv")
test=read_csv("D:/santander/test.csv")
train[is.na(train)]=0
test[is.na(test)]=0
train_names <- names(train)[-1]
for (i in train_names-1)
{
if (class(train[[i]]) == "integer")
{
u <- unique(train[[i]])
if (length(u) == 1)
{
train[[i]] <- NULL
test[[i]]<-NULL
}
for (i in train_names-1)
{
if (class(train[[i]]) == "integer")
{
u <- unique(train[[i]])
if (length(u) == 1)
{
train[[i]] <- NULL
test[[i]]<-NULL
}
/
for (i in train_names)
{
if (class(train[[i]]) == "integer")
{
u <- unique(train[[i]])
if (length(u) == 1)
{
train[[i]] <- NULL
test[[i]]<-NULL
}
pca=princomp(as.matrix(train[,-c(train$ID,train$TARGET)]),cor=TRUE)
library(readr) # CSV file I/O, e.g. the read_csv function
library(xgboost)
# Input data files are available in the "../input/" directory.
# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory
# Reading the data
dat_train=read_csv("D:/santander/train.csv", stringsAsFactors = F)
dat_test=read_csv("D:/santander/test.csv", stringsAsFactors = F)
# Mergin the test and train data
dat_test$TARGET <- NA
all_dat <- rbind(dat_train, dat_test)
# Removing the constant variables
train_names <- names(dat_train)[-1]
for (i in train_names)
{
if (class(all_dat[[i]]) == "integer")
{
u <- unique(all_dat[[i]])
if (length(u) == 1)
{
all_dat[[i]] <- NULL
}
train_names <- names(all_dat)[-1]
fac <- data.frame(fac = integer())
for(i in 1:length(train_names))
{
if(i != length(train_names))
{
for (k in (i+1):length(train_names))
{
if(identical(all_dat[,i], all_dat[,k]) == TRUE)
{
fac <- rbind(fac, data.frame(fac = k))
}
same <- unique(fac$fac)
all_dat <- all_dat[,-same]
library(readr) # CSV file I/O, e.g. the read_csv function
library(xgboost)
# Input data files are available in the "../input/" directory.
# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory
# Reading the data
dat_train=read_csv("D:/santander/train.csv", stringsAsFactors = F)
dat_test=read_csv("D:/santander/test.csv", stringsAsFactors = F)
# Mergin the test and train data
dat_test$TARGET <- NA
library(readr) # CSV file I/O, e.g. the read_csv function
library(xgboost)
# Input data files are available in the "../input/" directory.
# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory
# Reading the data
dat_train=read_csv("D:/santander/train.csv")
dat_test=read_csv("D:/santander/test.csv")
# Mergin the test and train data
dat_test$TARGET <- NA
all_dat <- rbind(dat_train, dat_test)
for(i in 1:length(train_names))
{
if(i != length(train_names))
{
for (k in (i+1):length(train_names))
{
if(identical(all_dat[,i], all_dat[,k]) == TRUE)
{
fac <- rbind(fac, data.frame(fac = k))
}
train_names <- names(dat_train)[-1]
for (i in train_names)
{
if (class(all_dat[[i]]) == "integer")
{
u <- unique(all_dat[[i]])
if (length(u) == 1)
{
all_dat[[i]] <- NULL
}
train_names <- names(all_dat)[-1]
fac <- data.frame(fac = integer())
for(i in 1:length(train_names))
{
if(i != length(train_names))
{
for (k in (i+1):length(train_names))
{
if(identical(all_dat[,i], all_dat[,k]) == TRUE)
{
fac <- rbind(fac, data.frame(fac = k))
}
same <- unique(fac$fac)
all_dat <- all_dat[,-same]
train <- all_dat[1:nrow(dat_train), ]
test <- all_dat[-(1:nrow(dat_train)), ]
write_csv(train,"D/santander/train_NoConstan.csv")
write_csv(test,"D/santander/test_NoConstan.csv")
which[is.na(train)]
train[ID]
train[c(ID)]
train[train$ID]
train[[ID]]
library(readr)
library(xgboost)
library(stats)
train=read_csv("D:/santander/train_NoConstan.csv")
test=read_csv("D:/santander/test_NoConstan.csv")
library(readr) # CSV file I/O, e.g. the read_csv function
library(xgboost)
# Input data files are available in the "../input/" directory.
# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory
# Reading the data
dat_train=read_csv("D:/santander/train.csv")
dat_test=read_csv("D:/santander/test.csv")
# Mergin the test and train data
dat_test$TARGET <- NA
all_dat <- rbind(dat_train, dat_test)
# Removing the constant variables
train_names <- names(dat_train)[-1]
for (i in train_names)
{
if (class(all_dat[[i]]) == "integer")
{
u <- unique(all_dat[[i]])
if (length(u) == 1)
{
all_dat[[i]] <- NULL
}
train_names <- names(all_dat)[-1]
fac <- data.frame(fac = integer())
for(i in 1:length(train_names))
{
if(i != length(train_names))
{
for (k in (i+1):length(train_names))
{
if(identical(all_dat[,i], all_dat[,k]) == TRUE)
{
fac <- rbind(fac, data.frame(fac = k))
}
same <- unique(fac$fac)
all_dat <- all_dat[,-same]
# Splitting the data for model
train <- all_dat[1:nrow(dat_train), ]
test <- all_dat[-(1:nrow(dat_train)), ]
y=as.numeric(dat_train$TARGET)
train[is.na(train)]=0
test[is.na(test)]=0
write_csv(test,"D:/santander/train1.csv")
write_csv(test,"D:/santander/test1.csv")
write_csv(train,"D:/santander/train1.csv")
library(readr)
library(xgboost)
library(stats)
train=read_csv("D:/santander/train1.csv")
test=read_csv("D:/santander/test1.csv")
train[is.na(train)]=0
test[is.na(test)]=0
train_names <- names(train)[-1]
for (i in train_names)
{
if (class(train[[i]]) == "integer")
{
u <- unique(train[[i]])
if (length(u) == 1)
{
train[[i]] <- NULL
test[[i]]<-NULL
}
pca=princomp(as.matrix(train[,-c(train$ID,train$TARGET)]),cor=TRUE)
train_reduced=predict(pca,train)
test_reduced=predict(pca,as.matrix(test[,-c(train$ID,train$TARGET)]))
dim(test_reduced)
y=as.numeric(train$TARGET)
param <- list("objective" = "binary:logistic",booster = "gbtree",
"eval_metric" = "auc",colsample_bytree = 0.85,
subsample = 0.95)
param1 <- list("objective" = "binary:logistic",
booster = "gbtree",
"eval_metric" = "auc",
colsample_bytree = 0.85,
subsample = 0.75)
xgb.model=xgboost(data = train_reduced,
label=y,
params = param1,
nrounds = 8,
max.depth = 10,
eta = 0.02,
maximize = T)
nrow(train)
ncol(train)
train$ID
train$TARGET
train1=as.matrix(train[,-c(train$ID,train$TARGET)])
ncol(train1)
ncol(train)
ncol(train_reduced)
train1=train[,-c(train$ID,train$TARGET)]
ncol(train1)
ncol(train)
library(readr)
train=read_csv("D:/santander/train.csv")
summary(train$TARGET)
train[,train$TARGET==1]
library(dplyr)
select(train,TARGET>0)
?select
?"dplyr"
browseVignettes(package = "dplyr")
?filter()
train1=filter(train,TARGET>0)
summary(train1)
summary(train1$TARGET)
count(train$TARGET)
ncol(train1)
View(train1)
train2=filter(train,TARGET<1)
ncol(train2)
nrow(train1)
nrow(train2)
nrow(train)
nrow(test)
test=read_csv("D:/santander/test.csv")
nrow(test)
?sample_n
train2=filter(train,TARGET<1)
s=sample_n(train2,20000)
source('D:/RScriptGit/preData.R')
source('D:/RScriptGit/preData.R', encoding = 'UTF-8')
summary(preds)
preds=predict(xgb.model,as.matrix(test))
submission <- data.frame(ID=test$ID, TARGET=preds)
write.csv(submission, "submission.csv", row.names = F)
write.csv(submission, "D:/santander/submission.csv", row.names = F)
sumary(preds)
summary(preds)
library(dplyr)
d=filter(preds,preds>0.5)
d=filter(as.matrix(preds),preds>0.5)
preds[preds>0.5]
ncol(preds[preds>0.5])
nrow(preds[preds>0.5])
a=preds[preds>0.5]
count(a)
a
preds[preds>0.5]=0.9
preds[preds<=0.5]=0.1
summary(preds)
submission <- data.frame(ID=test$ID, TARGET=preds)
write.csv(submission, "D:/santander/submission1.csv", row.names = F)
source('D:/RScriptGit/preData.R', encoding = 'UTF-8')
summary(preds)
install_github('rCharts', 'ramnathv')
library(devtools)
install_github('rCharts', 'ramnathv')
library(rCharts)
names(iris) = gsub("\\.", "", names(iris))
rPlot(SepalLength ~ SepalWidth | Species, data = iris, color = 'Species', type = 'point')
library(rCharts)
names(iris) = gsub("\\.", "", names(iris))
rPlot(SepalLength ~ SepalWidth | Species, data = iris, color = 'Species', type = 'point')
install.packages('networkD3')
install.packages('d3heatmap')
library(d3heatmap)
d3heatmap(mtcars, scale="column", colors="Blues")
